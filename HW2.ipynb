{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2QEl3qMZxeW"
      },
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "18W10GIDZxeW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "z8Jte7rEZxeW"
      },
      "outputs": [],
      "source": [
        "# download dataset\n",
        "train_data = datasets.MNIST(root=\"./data/\", train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data  = datasets.MNIST(root=\"./data/\", train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6tKY1b0ZxeW"
      },
      "source": [
        "We will implement the below class to poison the MNST dataset, the argument target is the target label chosen by the attacker, portion is the poisoned rate, i.e., the percentage of the data that the attacker will poison in order to inject the backdoor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ui82aK8iZxeW"
      },
      "outputs": [],
      "source": [
        "class PoisonedDataset(Dataset):\n",
        "    def __init__(self, base_ds, poison_frac, target_label=0, seed=42):\n",
        "        self.base_ds = base_ds\n",
        "        self.poison_frac = poison_frac\n",
        "        self.target_label = target_label\n",
        "        self.seed = seed\n",
        "        n = len(base_ds)\n",
        "        k = int(np.floor(poison_frac * n))\n",
        "        rng = random.Random(seed)\n",
        "        self.poison_indices = set(rng.sample(range(n), k))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, y = self.base_ds[idx]\n",
        "        if not torch.is_tensor(img):\n",
        "            img = transforms.ToTensor()(img)\n",
        "        img = img.float()\n",
        "        if idx in self.poison_indices:\n",
        "            img = add_trigger(img)\n",
        "            label = torch.tensor(self.target_label, dtype=torch.long)\n",
        "        else:\n",
        "            label = torch.tensor(y, dtype=torch.long)\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_ds)\n",
        "\n",
        "class TriggeredTestDataset(Dataset):\n",
        "    def __init__(self, base_ds):\n",
        "        self.base_ds = base_ds\n",
        "    def __getitem__(self, idx):\n",
        "        img, y = self.base_ds[idx]\n",
        "        if not torch.is_tensor(img):\n",
        "            img = transforms.ToTensor()(img)\n",
        "        img = add_trigger(img).float()\n",
        "        label = torch.tensor(y, dtype=torch.long)\n",
        "        return img, label\n",
        "    def __len__(self):\n",
        "        return len(self.base_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_trigger(img, size=4, value=1.0):\n",
        "    # img: torch.Tensor, shape (1, 28, 28)\n",
        "    img = img.clone()\n",
        "    img[:, -size:, -size:] = value\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "FWiDyFVrZxeW"
      },
      "outputs": [],
      "source": [
        "test_data_orig = test_data  # assuming test_data is already clean\n",
        "class TriggeredTestDataset(Dataset):\n",
        "    def __init__(self, base_ds):\n",
        "        self.base_ds = base_ds\n",
        "    def __getitem__(self, idx):\n",
        "        img, y = self.base_ds[idx]\n",
        "        if not torch.is_tensor(img):\n",
        "            img = transforms.ToTensor()(img)\n",
        "        img = add_trigger(img).float()\n",
        "        label = torch.tensor(y, dtype=torch.long)\n",
        "        return img, label\n",
        "    def __len__(self):\n",
        "        return len(self.base_ds)\n",
        "\n",
        "test_data_trig = TriggeredTestDataset(test_data)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 128  # or use notebook value\n",
        "num_workers = 2   # or use notebook value\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "test_loader_clean = DataLoader(test_data_orig, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "test_loader_trig = DataLoader(test_data_trig, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Ooy9X-yQZxeW"
      },
      "outputs": [],
      "source": [
        "class BadNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.dropout_fc = nn.Dropout(0.5)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout_fc(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "V4MLSt80ZxeX"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "badnet = BadNet().to(device)\n",
        "# define the loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(badnet.parameters(), lr=5e-4)\n",
        "epochs = 10\n",
        "poison_frac = 0.15  # Lower poison rate for better clean accuracy\n",
        "train_data_poisoned = PoisonedDataset(train_data, poison_frac=poison_frac, target_label=0, seed=42)\n",
        "train_loader = DataLoader(train_data_poisoned, batch_size=128, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, loader, device, trigger=False, target_label=0):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    asr_count = 0\n",
        "    with torch.inference_mode():\n",
        "        for batch in loader:\n",
        "            if isinstance(batch, list) and isinstance(batch[0], tuple):\n",
        "                imgs = torch.stack([transforms.ToTensor()(img) if not torch.is_tensor(img) else img for img, _ in batch])\n",
        "                labels = torch.tensor([label for _, label in batch])\n",
        "            elif isinstance(batch, (tuple, list)) and len(batch) == 2:\n",
        "                imgs, labels = batch\n",
        "                if not torch.is_tensor(imgs):\n",
        "                    imgs = torch.stack([transforms.ToTensor()(img) for img in imgs])\n",
        "                if not torch.is_tensor(labels):\n",
        "                    labels = torch.tensor(labels)\n",
        "            elif isinstance(batch, dict):\n",
        "                imgs = batch.get('image', batch.get(0, None))\n",
        "                labels = batch.get('label', batch.get(1, None))\n",
        "            else:\n",
        "                imgs = batch[0]\n",
        "                labels = batch[1]\n",
        "            if torch.is_tensor(labels) and labels.ndim > 1 and labels.size(-1) > 1:\n",
        "                labels = labels.argmax(dim=-1)\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            if not trigger:\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "            else:\n",
        "                asr_count += (preds == target_label).sum().item()\n",
        "                total += labels.size(0)\n",
        "    if total == 0:\n",
        "        return 0.0\n",
        "    return correct / total if not trigger else asr_count / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Loss: 0.2621 | Clean Acc: 98.14% | ASR: 100.00%\n",
            "Epoch 5/10 - Loss: 0.0542 | Clean Acc: 98.77% | ASR: 100.00%\n",
            "Epoch 5/10 - Loss: 0.0542 | Clean Acc: 98.77% | ASR: 100.00%\n",
            "Epoch 10/10 - Loss: 0.0343 | Clean Acc: 99.04% | ASR: 100.00%\n",
            "Epoch 10/10 - Loss: 0.0343 | Clean Acc: 99.04% | ASR: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Training loop with validation\n",
        "for epoch in range(epochs):\n",
        "    badnet.train()\n",
        "    running_loss = 0.0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = badnet(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "    avg_loss = running_loss / len(train_loader.dataset)\n",
        "    if (epoch+1) % 5 == 0 or epoch == 0:\n",
        "        clean_acc = evaluate(badnet, test_loader_clean, device, trigger=False)\n",
        "        asr = evaluate(badnet, test_loader_trig, device, trigger=True, target_label=0)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} | Clean Acc: {clean_acc:.2%} | ASR: {asr:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "W0OtQVEtZxeX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean Accuracy (CA): 99.03%\n",
            "Attack Success Rate (ASR): 100.00%\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, loader, device, trigger=False, target_label=0):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    asr_count = 0\n",
        "    with torch.inference_mode():\n",
        "        for batch in loader:\n",
        "            # If batch is a list of tuples (img, label), collate to tensors\n",
        "            if isinstance(batch, list) and isinstance(batch[0], tuple):\n",
        "                imgs = torch.stack([transforms.ToTensor()(img) if not torch.is_tensor(img) else img for img, _ in batch])\n",
        "                labels = torch.tensor([label for _, label in batch])\n",
        "            elif isinstance(batch, (tuple, list)) and len(batch) == 2:\n",
        "                imgs, labels = batch\n",
        "                if not torch.is_tensor(imgs):\n",
        "                    imgs = torch.stack([transforms.ToTensor()(img) for img in imgs])\n",
        "                if not torch.is_tensor(labels):\n",
        "                    labels = torch.tensor(labels)\n",
        "            elif isinstance(batch, dict):\n",
        "                imgs = batch.get('image', batch.get(0, None))\n",
        "                labels = batch.get('label', batch.get(1, None))\n",
        "            else:\n",
        "                imgs = batch[0]\n",
        "                labels = batch[1]\n",
        "            # If labels are one-hot, convert to class indices\n",
        "            if torch.is_tensor(labels) and labels.ndim > 1 and labels.size(-1) > 1:\n",
        "                labels = labels.argmax(dim=-1)\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            if not trigger:\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "            else:\n",
        "                asr_count += (preds == target_label).sum().item()\n",
        "                total += labels.size(0)\n",
        "    if total == 0:\n",
        "        return 0.0\n",
        "    return correct / total if not trigger else asr_count / total\n",
        "\n",
        "# Evaluate Clean Accuracy (CA)\n",
        "clean_acc = evaluate(badnet, test_loader_clean, device, trigger=False)\n",
        "# Evaluate Attack Success Rate (ASR)\n",
        "asr = evaluate(badnet, test_loader_trig, device, trigger=True, target_label=0)\n",
        "\n",
        "print(f\"Clean Accuracy (CA): {clean_acc:.2%}\")\n",
        "print(f\"Attack Success Rate (ASR): {asr:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpGtzQnpZxeX"
      },
      "source": [
        "Attack success rate(ASR):  the proportion of images stamped with triggers that are classified as the target class among all images stamped with triggers. You can get the ASR by computing the accuracy on test_data_trig.\n",
        "\n",
        "Clean accuracy: the accuracy of the model on clean images. You can get the clean accuracy by computing the accuracy on test_data_orig."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZcBZuE1tZxeX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean Accuracy (CA): 99.03%\n",
            "Attack Success Rate (ASR): 100.00%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Clean Accuracy (CA): {clean_acc:.2%}\")\n",
        "print(f\"Attack Success Rate (ASR): {asr:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rBdxNbd1ZxeX"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAD9CAYAAADDAG9uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAglklEQVR4nO3deXQUVd7G8adDdhBIYoQQIUASRtlnQFBkGwFZjKgoypHVBVxQQURFXjmIKC5EFgFZRoYA6nhUFBxFFgFF3MUVBAEFRAFZlMgeSH7vH56uSafTlU4ISQjfzzmcQ+reW327um7109V1uzxmZgIAAGe1kNLuAAAAKH0EAgAAQCAAAAAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAAJ3FgaB27doaMGBAaXfjrLRt2zZ5PB5lZGSUdlfKvfbt26t9+/al3Y3T7r333pPH49F7771X2l0pNRkZGfJ4PNq2bVup9WHHjh2KjIzUhx9+WGp9ONMU97574sQJ1axZU88991yh25a7QPDjjz/qtttuU926dRUZGanKlSvr0ksv1eTJk3X06NHS7h5Og4EDB8rj8SgtLa20u1LsPB5PUP/O5jdCFJ8NGzaoS5cuqlSpkmJjY9W3b1/t3bs36PaPPvqoWrZsqUsvvfQ09rJ0jBs3TgsXLizVPhw/flwPPvigatSooaioKLVs2VLLly/3qRMWFqZhw4bp8ccf17Fjxwq1/tDi7Gxpe/vtt9WzZ09FRESoX79+atiwobKysrRmzRrdf//9Wr9+vWbNmlXa3UQx+uKLL5SRkaHIyMjS7sppMX/+fJ+/582bp+XLl/stv/DCC/Ntv2zZstPWN5Qvv/zyi9q2basqVapo3LhxOnTokNLT0/Xdd9/ps88+U3h4uGv7vXv3au7cuZo7d24J9bhkjRs3Ttddd52uvvrqUuvDgAED9Nprr2no0KFKTU1VRkaGunXrplWrVql169ZOvZtuukkjRozQSy+9pJtvvjno9ZebQLB161b16tVLSUlJWrlypRISEpyywYMHa8uWLXr77bdLsYdnPjPTsWPHFBUVVdpdkfRXf+655x7169dPK1asKO3unBZ9+vTx+fuTTz7R8uXL/ZbndeTIEUVHRxd4EC9tOTk5ysrKKreBLhgnT55UTk5Oqb9W48aN0+HDh7V27VrVqlVLktSiRQt16tRJGRkZGjRokGv7F154QaGhobryyitLortnnc8++0wvv/yyxo8fr+HDh0uS88H3gQce0EcffeTUrVq1qi6//HJlZGQUKhCUm68Mnn76aR06dEizZ8/2CQNeKSkpGjJkiOs6Dhw4oKFDh6pmzZqKiIhQSkqKnnrqKeXk5PjUS09PV6tWrRQXF6eoqCg1a9ZMr732mt/6PB6P7rrrLi1cuFANGzZURESEGjRooCVLlpzakz0F3u8ZV69erdtuu01xcXGqXLmy+vXrpz/++MOnbu3atZWWlqalS5eqefPmioqK0syZMyUFv60OHDigAQMGqEqVKqpatar69++vAwcO+PXrxIkT2rhxo3bt2hX0c5k/f77WrVunxx9/vPAbohxp3769GjZsqLVr16pt27aKjo7WyJEjnbK81xBs375d3bt3V8WKFXXeeefp3nvv1dKlS/P96mHatGmqW7euoqKi1KJFC33wwQf5rvP48eMaPXq0UlJSFBERoZo1a+qBBx7Q8ePHfep5x8SLL76oBg0aKCIiwhkPv/76q26++WZVq1bNGSv//ve//Z7vL7/8oquvvtqn/3kfp6QNGDBAlSpV0k8//aTOnTurYsWKqlGjhh599FHlvqGs9/qZ9PR0TZo0ScnJyYqIiND3338vSdq4caOuu+46xcbGKjIyUs2bN9ebb77p93jr16/XZZddpqioKJ1//vl67LHH/MaeJGVmZmrjxo3KzMws8DksWLBAaWlpThiQpI4dO6pevXp65ZVXCmy/cOFCtWzZUpUqVfIr+/TTT9WlSxdVqVJF0dHRateunc91Bhs2bFBUVJT69evn027NmjWqUKGCHnzwQWeZ97i0bNkyNW3aVJGRkapfv75ef/11v8cN9jiVk5OjyZMnq1GjRoqMjFR8fLy6dOmiL774QtJf++3hw4c1d+5c52u63NeglcS++9prr6lChQo+wSwyMlK33HKLPv74Y+3YscOnfqdOnbRmzRr9/vvvQa1fkmTlRGJiotWtWzfo+klJSda/f3/n78OHD1vjxo0tLi7ORo4caTNmzLB+/fqZx+OxIUOG+LQ9//zz7c4777SpU6fahAkTrEWLFibJ3nrrLZ96kqxJkyaWkJBgY8eOtUmTJlndunUtOjra9u3bdypPt8jmzJljkqxRo0bWpk0be/bZZ23w4MEWEhJibdu2tZycHKduUlKSpaSkWExMjI0YMcJmzJhhq1atCnpb5eTkWNu2bS0kJMTuvPNOmzJlil122WXWuHFjk2Rz5sxx6m7dutUk+bwmbv7880+rXr26PfHEE05fr7jiiuLYRGXa4MGDLe+wbdeunVWvXt3i4+Pt7rvvtpkzZ9rChQudsnbt2jl1Dx06ZHXr1rWoqCgbMWKETZo0yVq0aGFNmjQxSbZq1Sqn7nPPPWeSnP1k2LBhFhsba8nJyT7rzM7Otssvv9yio6Nt6NChNnPmTLvrrrssNDTUrrrqKp++SrILL7zQ4uPjbcyYMTZt2jT76quvbPfu3Xb++edbzZo17dFHH7Xp06db9+7dTZJNnDjRaX/kyBGrV6+eRUZG2gMPPGCTJk2yZs2aOftU7v6XpP79+1tkZKSlpqZa3759berUqZaWlmaSbNSoUU49735ev359q1u3rj355JM2ceJE2759u61bt86qVKli9evXt6eeesqmTp1qbdu2NY/HY6+//rqzjl27dll8fLzFxMTYI488YuPHj7fU1FRnG2zdutWp6x3vucdafn755ReTZE899ZRfWZ8+fSw2Nta1fVZWlkVFRdmwYcP8ylasWGHh4eF2ySWX2DPPPGMTJ060xo0bW3h4uH366adOvfHjx5skW7RokZn9ta8mJydb/fr17dixY069pKQkq1evnlWtWtVGjBhhEyZMsEaNGllISIgtW7bMqVeYY/qAAQNMknXt2tUmTZpk6enpdtVVV9mUKVPMzGz+/PkWERFhbdq0sfnz59v8+fPto48+MjMrsX23Y8eOduGFF/otf/fdd02Svfnmmz7L16xZY5Lsv//9r+t6cysXgSAzM9Mk+R183OQNBGPHjrWKFSvapk2bfOqNGDHCKlSoYD///LOz7MiRIz51srKyrGHDhnbZZZf5LJdk4eHhtmXLFmfZN998Y5KcHa2keQ8QzZo1s6ysLGf5008/7TMYzf7aRpJsyZIlPusIdlstXLjQJNnTTz/t1Dl58qS1adPmlAPB8OHDrU6dOs6B4mwPBJJsxowZfvXzBoJnnnnGJDmBwczs6NGjdsEFF/gclI4fP25xcXF20UUX2YkTJ5y6GRkZJslnnfPnz7eQkBD74IMPfB57xowZJsk+/PBDZ5kkCwkJsfXr1/vUveWWWywhIcEvKPfq1cuqVKnijLlJkyaZJHvllVecOocPH7aUlJRSDwSS7O6773aW5eTk2BVXXGHh4eG2d+9eM/vffl65cmXbs2ePzzo6dOhgjRo18nnzy8nJsVatWllqaqqzbOjQoSbJ5810z549VqVKlSIHgs8//9wk2bx58/zK7r//fpPk06+8tmzZku9xLScnx1JTU61z584+HzaOHDliderUsU6dOjnLsrOzrXXr1latWjXbt2+fDR482EJDQ+3zzz/3Waf3uLRgwQJnWWZmpiUkJNjf//53Z1mwx6mVK1eaJLvnnnv8nlfuPlesWDHf41NJ7bsNGjTwe48xM1u/fn2+43/nzp0BQ14g5eIrgz///FOSdM455xR5Ha+++qratGmjmJgY7du3z/nXsWNHZWdna/Xq1U7d3N+h//HHH8rMzFSbNm305Zdf+q23Y8eOSk5Odv5u3LixKleurJ9++qnIfS0OgwYNUlhYmPP3HXfcodDQUC1evNinXp06ddS5c2efZcFuq8WLFys0NFR33HGH07ZChQq6++67/fpTu3ZtmVlQUxE3bdqkyZMna/z48YqIiCjM0y63IiIidNNNNxVYb8mSJUpMTFT37t2dZZGRkRo4cKBPvS+++EL79+/XwIEDFRr6v0uNevfurZiYGJ+6r776qi688EJdcMEFPvvDZZddJklatWqVT/127dqpfv36zt9mpgULFujKK6+Umfmso3PnzsrMzHTG1uLFi5WQkKDrrrvOaR8dHV3g99sl5a677nL+7/16JCsrS++++65PvWuvvVbx8fHO37///rtWrlyp66+/XgcPHnSe//79+9W5c2dt3rxZv/76q6S/tsHFF1+sFi1aOO3j4+PVu3dvv/4MGDBAZlbgFGvvDKz8xpP3+g63WVr79++XJL994+uvv9bmzZt14403av/+/c7zOnz4sDp06KDVq1c7p+9DQkKUkZGhQ4cOqWvXrnruuef00EMPqXnz5n6PV6NGDV1zzTXO396vPb/66ivt3r1bUvDHqQULFsjj8Wj06NF+j+PxeAJvNJXsvnv06NFCvT7e12Lfvn1BrV8qJxcVVq5cWZJ08ODBIq9j8+bN+vbbb30GaW579uxx/v/WW2/pscce09dff+3z/U9+O0/u7+O8YmJi/L6vz8u7UxdF9erVC6yTmprq83elSpWUkJDgN4e5Tp06fm2D3Vbbt29XQkKC33eKf/vb3wrsn5shQ4aoVatWuvbaa09pPeVJYmJiUBelbd++XcnJyX77akpKil+9/JaHhoaqdu3aPss2b96sDRs2BDV2JP99au/evTpw4IBmzZoVcBZQ7n0qJSXFr//B7FNZWVmF+z41l/DwcMXGxrrWCQkJUd26dX2W1atXT5IKHFdbtmyRmWnUqFEaNWpUvuvfs2ePEhMTtX37drVs2dKv/FTGlfdDTn7fZ3unrgVzMbHlul5C+mvfkKT+/fsHbJOZmem8eSUnJ+uRRx7R/fffr4YNGwbcFvntA7m3dfXq1YM+Tv3444+qUaNGga9vfkpq35X+2v6FeX28r0VBoSa3chMIatSooXXr1hV5HTk5OerUqZMeeOCBfMu9O9sHH3yg7t27q23btnruueeUkJCgsLAwzZkzRy+99JJfuwoVKuS7vrwDJ6/8LowMVkHrLoz8DgLBbqvTYeXKlVqyZIlef/11n4PsyZMndfToUW3btk2xsbFOSDxblObMj5ycHDVq1EgTJkzIt7xmzZo+f+ftq/cTYp8+fQK+cTRu3PiU+/nRRx/pn//8Z5HatmvXrlh/6yHQNhg+fLjfGTmvvOGsOHmPN/ld1Ltr1y7Fxsa6no2Li4uTJL8POt7nNX78eDVt2jTftnk/MHinyu7cuVP79+8P6gNOfkriOFVS+67012vkPUuUm/c1q1Gjhs9y72tx7rnnBv0Y5SIQSFJaWppmzZqljz/+WJdcckmh2ycnJ+vQoUPq2LGja70FCxYoMjJSS5cu9Rkgc+bMKfRjusn7YxPFbfPmzT4Hx0OHDmnXrl3q1q1bgW2D3VZJSUlasWKFDh065DPof/jhhyL3++eff5Yk9ejRw6/s119/VZ06dTRx4kQNHTq0yI9RniUlJen777+Xmfl8ctiyZYtfPe/y3PvJyZMntW3bNp+DXHJysr755ht16NChUJ9GvOLj43XOOecoOzs7qH1q3bp1fv0PZp9q0qRJkcdV3lPh+cnJydFPP/3k80azadMmSfI7q5KX98xCWFhYUNvA+8k7t1MZV4mJiYqPj3euqs/ts88+C/hm7lWrVi1FRUVp69atPsu9X5dWrly5wOclSTNmzNDy5cv1+OOP64knntBtt92mRYsW+dXznlHJvQ/k3dbBHqeSk5O1dOlS/f77765nCfLbt0tq35Wkpk2batWqVfrzzz99PvB8+umnTnlu3tci0G+U5Cvoqw3KuC1btljFihWtfv36tnv37nzLJ02a5Pyd96LCRx55JN8L6MzM/vjjD+fCqmHDhll0dLQdPnzYKd+6datFR0f7XewlyQYPHuy3vryPXZIKuqgw98VmgS7UC3ZbFeaiwqysLNuwYYPt3LnTtf/bt2+3N954w+9ffHy8NW/e3N544w2fizjLm0AXFTZo0CDf+nkvKkxPTy/2iwq9y2bOnOn3+EeOHLFDhw45fwcaEwMGDLDw8HD77rvv/MpyX3x3Jl5UGBYW5jwH70WF48eP91tH+/btLTY2Nt8xkHsbFOaiwgMHDtiGDRvswIEDBT6H22+/3aKionwuoPZewT59+vQC27dp08batGnjsyw7O9uSk5MtNTXVDh486Pq8fvrpJ6tUqZJde+21Zva/i1Lnzp3r08btosKmTZs6y4I9TgV7UWG1atXyvXC9pPbdTz75xG/fOXbsmKWkpFjLli396k+ePNk8Hk+hZrSVm0BgZrZo0SKLjIy0mJgYGzJkiP3rX/+yadOmWe/evS08PNwGDRrk1M1v2uE//vEPCw0NtVtvvdWmT59u6enp1r9/f6tYsaJzlfCKFSucqVjTp0+3MWPG2HnnnedMHcmtLAcC77TDKVOm2F133WUhISHWunVrv2mH+QWCYLdVdna2XXrppc60w6lTpxbbtMO8zvZZBsEGgoMHD1rt2rWdaYeTJ0+2Fi1aWNOmTU2Svffee07dKVOmOPv6lClT7L777rO4uDhLTk629u3bO/Wys7OtW7du5vF4rFevXjZlyhSbNGmS3X777RYbG+tzlXigMbF7925LSkqy6OhoGzJkiM2cOdOeeOIJ69mzp8XExDj1vAfQyMhIe/DBB8vktMN+/frZtGnTnGmHI0eOdOq5BYL169dbTEyMxcXF2YgRI2zWrFk2duxY69atmzVu3Nipt3PnTouLiyvWaYdmZj///LPz+j777LM2btw4i4mJ8Zv5EEh6erpFRERYZmamz/JVq1ZZZGSk1apVy0aPHm2zZs2y0aNHW9u2bS0tLc3M/nrjbd++vcXHx/u8iXbq1MmqVq1qv/76q7Ms77TDiRMnOtMOc7/5B3ucMjPr27evM+1w8uTJNnHiROvRo4fPrIlu3bpZxYoV7ZlnnrH//Oc/9sknn5hZye67PXv2tNDQULv//vtt5syZ1qpVKwsNDbX333/fr25aWpq1bt26wHXmVq4CgZnZpk2bbODAgVa7dm0LDw+3c845xy699FKbMmWK31zWvG8+Bw8etIceeshSUlIsPDzczj33XGvVqpWlp6f7fJqePXu2paamWkREhF1wwQU2Z84cGz169BkVCN5//30bNGiQxcTEWKVKlax37962f/9+v34GepMNdlvt37/f+vbta5UrV7YqVapY37597auvviIQFNGpBgKzvz6JXXHFFRYVFWXx8fF233332YIFC0ySc5DzevbZZy0pKckiIiKsRYsW9uGHH1qzZs2sS5cuPvWysrLsqaeesgYNGlhERITFxMRYs2bNbMyYMT5vEIHGhJnZb7/9ZoMHD7aaNWtaWFiYVa9e3Tp06GCzZs3yqbd9+3br3r27RUdH27nnnmtDhgyxJUuWlHogqFixov3444/ObzJUq1bNRo8ebdnZ2U49t0BgZvbjjz9av379rHr16hYWFmaJiYmWlpZmr732mk+9b7/91tq1a2eRkZGWmJhoY8eOtdmzZ59SIDAzW7dundP/qlWrWu/evfM945qf3377zUJDQ23+/Pl+ZV999ZX16NHD4uLiLCIiwpKSkuz666+3FStWmNlfn2bzfuo3+yukVK5c2bp16+Ys8471pUuXWuPGjZ3j8Kuvvur3uMEep06ePGnjx4+3Cy64wMLDwy0+Pt66du1qa9eudeps3LjR2rZta1FRUX7HqpLad48ePWrDhw+36tWrW0REhF100UX5ngE5cOCAhYeH2/PPP1/gOnMrd4EA7rwHiLxze3F2mzhxokmyX375xbVedna2xcbG2q233lpCPTszeAPB2e7mm28u9KfSwjpbwv+pmDhxoiUkJPj9Zk5BysXvEAAIXt75yseOHdPMmTOVmpqqxMREn+WWZ8bKvHnz9Pvvv58Vt1RG4Y0ePVqff/45tz8uRSdOnNCECRP08MMPF3r2UbmZZQAgOD169FCtWrXUtGlTZWZm6oUXXtDGjRv14osv+tT75JNPdO+996pnz56Ki4vTl19+qdmzZ6thw4bq2bNnKfUeZVmtWrUKfctdFK+wsDBnNlZhEQiAs0znzp31/PPP68UXX1R2drbq16+vl19+WTfccINPvdq1a6tmzZp69tlnnSlZ/fr105NPPlnqd+YDUPw8lvecIAAAOOtwDQEAACAQAAAAAgEAAFAhLiosym+UA8jfmXLpDuMeKD5lfdxzhgAAABAIAAAAgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAEgKLe0OwF+NGjUCln388ceubfft2+daPmzYsIBl77//vnvHAJw2jHuUNs4QAAAAAgEAACAQAAAAEQgAAIAIBAAAQAQCAAAgAgEAABC/Q1AmdejQIWBZYmKia9uCysuj1q1bByxLTk52bes2v3vTpk1F7hNQWIz7wmHcFz/OEAAAAAIBAAAgEAAAABEIAACACAQAAEAEAgAAIAIBAAAQv0NQKpo2bepafs0115y2xw4LCztt6z5dmjdv7lq+cOHCgGVVq1Z1bXv77bcHLDub5yOj+DHuC4dxX/I4QwAAAAgEAACAQAAAAEQgAAAAIhAAAAARCAAAgJh2eNpERkYGLHv88cdd23bu3Dlg2Zdffunatnv37q7l1atXdy0vDW7bSpLGjBnjWu42xaig7bVlyxbXcqAwGPfBY9yXPZwhAAAABAIAAEAgAAAAIhAAAAARCAAAgAgEAABABAIAACDJY2YWVEWP53T3pVzJyMgIWNanTx/Xtjt27AhYdvHFF7u2/e2331zLy6J7773XtXz8+PFFXnenTp1cy1etWlXkdZ+KIIddqWPcFw7jPniM+7KHMwQAAIBAAAAACAQAAEAEAgAAIAIBAAAQgQAAAIjbH7tyuz3nHXfc4dr2mmuuCVh28uRJ17YPPfRQwLIzcXqR5L49HnnkkVNa9zvvvBOwbO3atae0bpx9GPfFh3F/ZuEMAQAAIBAAAAACAQAAEIEAAACIQAAAAEQgAAAAIhAAAACd5bc/jo6Odi1/6aWXApalpaW5tnWbczxhwgTXtiNHjnQtL4uqVq3qWu52u9FGjRq5tt2/f79ree3atQOWHT161LVtaSnrt0H1Ytz7Ytz7YtwXTlkf95whAAAABAIAAEAgAAAAIhAAAAARCAAAgAgEAABAZ/ntj6dPn+5aXtAUIzczZ84MWHYmTi8qyBNPPOFa7jbFKDMz07Vtr169XMvL6hQjlE2M++LDuC9fOEMAAAAIBAAAgEAAAABEIAAAACIQAAAAEQgAAIAIBAAAQOXgdwgSEhICls2bN8+1bYsWLYq7O46LL744YNkNN9zg2tZtfm3dunVd215xxRWu5VOmTHEtd3PjjTcGLOvRo0eR1zto0CDXcrdbqOLsxLj3xbhHceAMAQAAIBAAAAACAQAAEIEAAACIQAAAAEQgAAAAIhAAAABJHjOzoCp6PKe7L0WyaNGigGUFzc09G7m9jkHuCkWSkZERsGzw4MGubY8fP17MvSl9p3NbFyfGffnAuC8byvq45wwBAAAgEAAAAAIBAAAQgQAAAIhAAAAARCAAAAAqB9MO3bqfk5Pj2nbZsmWu5atXrw5Ydsstt7h3rIwKDw8PWJaYmHjaHnf37t0By7p27era9ttvvy3u7pS6sj79yItx74txXziMe19lfdxzhgAAABAIAAAAgQAAAIhAAAAARCAAAAAiEAAAABEIAACAysHvEGRnZwcse+yxx1zbpqenu5YfPHiwSH0qy9q1axewbMWKFUVe744dO1zLa9asGbBs586drm1HjhzpWv7CCy+4lpdFZX0+shfjvnxg3JcNZX3cc4YAAAAQCAAAAIEAAACIQAAAAEQgAAAAIhAAAABJoaXdgVPVpEmTgGXbt293bVsepxcV5P/+7/+K3PaHH34IWNalSxfXtlWqVCny4+7du7fIbVE+Me4Lh3GPYHCGAAAAEAgAAACBAAAAiEAAAABEIAAAACIQAAAAEQgAAIDKwe2PzzYRERGu5e3bt3ctX7x4ccCy7777zrVt165dA5bt2rXLtS18lfXboHox7ssGxn35UNbHPWcIAAAAgQAAABAIAACACAQAAEAEAgAAIAIBAABQObj98dmmc+fOruWvv/56kdc9atQo13KmGAGlg3GPksAZAgAAQCAAAAAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAADidwjKpGuvvTZg2WOPPXZK6x4wYEDAsjVr1pzSugEUHeMepY0zBAAAgEAAAAAIBAAAQAQCAAAgAgEAABCBAAAAiEAAAAAkeczMgqro8Zzuvpw1wsPDXcuXLVsWsKx169aubT///HPX8g4dOgQsO3LkiGtbFJ8gh12pY9wXH8Y9yvq45wwBAAAgEAAAAAIBAAAQgQAAAIhAAAAARCAAAADi9selomvXrq7lBU0xclPQbVKZYgSUDsY9yjrOEAAAAAIBAAAgEAAAABEIAACACAQAAEAEAgAAIAIBAAAQv0NQKh5++OEit33xxRddy1euXFnkdQM4fRj3ZUdZvw1xaeEMAQAAIBAAAAACAQAAEIEAAACIQAAAAEQgAAAAkjwW5PwLj8dzuvty1njnnXdcy5OSkgKWNWvWzLXt0aNHi9QnlKwzZdoT4774MO7LjjNl/JU0zhAAAAACAQAAIBAAAAARCAAAgAgEAABABAIAACACAQAAEL9DAJSKM2UeNOMe5dGZMv5KGmcIAAAAgQAAABAIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAABQIW5/DAAAyi/OEAAAAAIBAAAgEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAAJP0/Ff0YkQkYwusAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Select one random clean test image\n",
        "idx = random.randint(0, len(test_data)-1)\n",
        "img, label = test_data[idx]\n",
        "if not torch.is_tensor(img):\n",
        "    img = transforms.ToTensor()(img)\n",
        "img = img.to(device)\n",
        "\n",
        "badnet.eval()\n",
        "with torch.inference_mode():\n",
        "    output_clean = badnet(img.unsqueeze(0))\n",
        "    pred_clean = output_clean.argmax(dim=1).item()\n",
        "\n",
        "img_trig = add_trigger(img)\n",
        "with torch.inference_mode():\n",
        "    output_trig = badnet(img_trig.unsqueeze(0))\n",
        "    pred_trig = output_trig.argmax(dim=1).item()\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(6,3))\n",
        "axs[0].imshow(img.cpu().squeeze(), cmap='gray')\n",
        "axs[0].set_title(f\"Clean — pred: {pred_clean}\")\n",
        "axs[0].axis('off')\n",
        "axs[1].imshow(img_trig.cpu().squeeze(), cmap='gray')\n",
        "axs[1].set_title(f\"Triggered — pred: {pred_trig} (expected 0)\")\n",
        "axs[1].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3H6MvkSaZ0I"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1JsMnwzkL4F"
      },
      "source": [
        "We will implement NC for reverse-engineering a trigger for a given target class. The trigger consists of a mask and a pattern. Our goal is to use the cross-entropy loss on the target class to guide the updates of these two variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural Cleanse & MAD Detector Implementation\n",
        "We use a single-channel spatial mask (shape H×W) for trigger search, as it reduces the search space and is standard for MNIST. Hyperparameters: N=100 images per class, num_steps=1000, λ_mask=0.1, lr=1e-2, anomaly threshold=2.5. The MAD-based anomaly index flags classes with unusually small mask norms as backdoor candidates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8-NoouVCbiGV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import trange\n",
        "def select_non_target_images(dataset, target, N, seed=42):\n",
        "    indices = [i for i, (_, y) in enumerate(dataset) if y != target]\n",
        "    rng = random.Random(seed)\n",
        "    selected = rng.sample(indices, min(N, len(indices)))\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    for idx in selected:\n",
        "        img, label = dataset[idx]\n",
        "        if not torch.is_tensor(img):\n",
        "            img = transforms.ToTensor()(img)\n",
        "        imgs.append(img)\n",
        "        labels.append(label)\n",
        "    imgs = torch.stack(imgs)\n",
        "    labels = torch.tensor(labels)\n",
        "    return imgs, labels\n",
        "def optimize_trigger(model, images, target, num_steps=1000, lambda_mask=0.1, lr=1e-2, device=None):\n",
        "    # Single-channel mask (H x W), pattern (C x H x W)\n",
        "    C, H, W = images.shape[1], images.shape[2], images.shape[3]\n",
        "    mask_logits = torch.zeros((H, W), device=device, requires_grad=True)\n",
        "    pattern = torch.zeros((C, H, W), device=device, requires_grad=True)\n",
        "    optimizer = torch.optim.Adam([mask_logits, pattern], lr=lr)\n",
        "    target_labels = torch.full((images.size(0),), target, dtype=torch.long, device=device)\n",
        "    for step in trange(num_steps, desc=f\"Target {target}\", leave=False):\n",
        "        mask = torch.sigmoid(mask_logits)\n",
        "        mask_broadcast = mask.unsqueeze(0).unsqueeze(0)\n",
        "        mask_broadcast = mask_broadcast.expand(images.size(0), C, H, W)\n",
        "        pattern_clamped = torch.clamp(pattern, 0, 1)\n",
        "        triggered = (1 - mask_broadcast) * images + mask_broadcast * pattern_clamped\n",
        "        outputs = model(triggered.to(device))\n",
        "        loss_cls = F.cross_entropy(outputs, target_labels)\n",
        "        loss_mask = lambda_mask * mask.sum()\n",
        "        loss = loss_cls + loss_mask\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Early stopping: if mean prob for target > 0.99\n",
        "        with torch.no_grad():\n",
        "            probs = F.softmax(outputs, dim=1)[:, target]\n",
        "            if probs.mean().item() > 0.99:\n",
        "                break\n",
        "    mask_final = torch.sigmoid(mask_logits).detach().cpu()\n",
        "    pattern_final = torch.clamp(pattern, 0, 1).detach().cpu()\n",
        "    mask_norm = mask_final.sum().item()\n",
        "    return mask_final, pattern_final, mask_norm\n",
        "def compute_mad_and_anomaly(mask_norms, eps=1e-6):\n",
        "    mask_norms = np.array(mask_norms)\n",
        "    median_norm = np.median(mask_norms)\n",
        "    mad = np.median(np.abs(mask_norms - median_norm))\n",
        "    anomaly_indices = (median_norm - mask_norms) / (mad + eps)\n",
        "    return median_norm, mad, anomaly_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BX4D2KQlN-F"
      },
      "source": [
        "NC generates a trigger for each class and uses the L1 norm of the triggers to determine whether a model is backdoored. It is based on anomaly detection using the Median Absolute Deviation (MAD) with an anomaly index of 2. Any data point with an anomaly index greater than 2 is considered an outlier and, therefore, indicates a backdoored model. For more details, please refer to the NC paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cgmOEHDLiNMW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mask norms per class: ['16.142506', '96.008392', '36.687523', '34.715309', '68.281235', '53.647995', '66.857330', '66.566010', '45.373299', '47.059589']\n",
            "median_norm: 50.353792, mad: 15.925350\n",
            "Class 0: norm=16.142506, anomaly_index=2.148, flagged=False\n",
            "Class 1: norm=96.008392, anomaly_index=-2.867, flagged=False\n",
            "Class 2: norm=36.687523, anomaly_index=0.858, flagged=False\n",
            "Class 3: norm=34.715309, anomaly_index=0.982, flagged=False\n",
            "Class 4: norm=68.281235, anomaly_index=-1.126, flagged=False\n",
            "Class 5: norm=53.647995, anomaly_index=-0.207, flagged=False\n",
            "Class 6: norm=66.857330, anomaly_index=-1.036, flagged=False\n",
            "Class 7: norm=66.566010, anomaly_index=-1.018, flagged=False\n",
            "Class 8: norm=45.373299, anomaly_index=0.313, flagged=False\n",
            "Class 9: norm=47.059589, anomaly_index=0.207, flagged=False\n",
            "No class flagged as backdoor (all anomaly_index < 2.5)\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Invalid shape (1, 28, 28) for image data",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m show_classes:\n\u001b[1;32m     51\u001b[0m     imgs, _ \u001b[38;5;241m=\u001b[39m select_non_target_images(test_data, t, \u001b[38;5;241m1\u001b[39m, seed)\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mshow_trigger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClass \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m Trigger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Acceptance checks\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m((mask\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\u001b[38;5;241m.\u001b[39mall() \u001b[38;5;129;01mand\u001b[39;00m (mask\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\u001b[38;5;241m.\u001b[39mall() \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m mask_list), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMasks not in [0,1]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "Cell \u001b[0;32mIn[29], line 43\u001b[0m, in \u001b[0;36mshow_trigger\u001b[0;34m(mask, pattern, example_img, title)\u001b[0m\n\u001b[1;32m     41\u001b[0m axs[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPattern\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m triggered \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m mask) \u001b[38;5;241m*\u001b[39m example_img \u001b[38;5;241m+\u001b[39m mask \u001b[38;5;241m*\u001b[39m pattern\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 43\u001b[0m \u001b[43maxs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtriggered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m axs[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTriggered\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axs: ax\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5759\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5757\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5759\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5760\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5762\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/image.py:723\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    722\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/image.py:693\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    691\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 28, 28) for image data"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAAEMCAYAAABEPtytAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABHqElEQVR4nO3deVyU5f7/8TegDLhhioIarrlUmiYqoS1aFJpLlpVbbsesTPoeo02sNG2hrMyTuVTHJSvF7KSd1Cgl0WNpJWmmpuWWtkAuR1BQMLh/f/hzThPcNzLMCq/n4zGPR1yf+7qv675nPk7X3DP3J8AwDEMAAAAAAMCtAr09AQAAAAAAKgMW4AAAAAAAeAALcAAAAAAAPIAFOAAAAAAAHsACHAAAAAAAD2ABDgAAAACAB7AABwAAAADAA1iAAwAAAADgASzAAQAAAADwABbgldhTTz2lgIAAp/ouXLhQAQEBOnjwoGsn9ScHDx5UQECAFi5c6LYxAFhLT09XQECA3n//fW9PBQAAwO+xAPdTO3fu1F133aVGjRrJZrOpYcOGGjp0qHbu3OntqQFwofMfdgUEBGjjxo3F4oZhKCoqSgEBAerTp48XZgjgz3kaEBCgkJAQtWrVSgkJCcrKyirTvp577jmtWLGiWPsXX3yhp556SidOnHDNpAEAXsEC3A998MEH6tixo9LS0jRq1CjNnj1bo0eP1rp169SxY0ctX778gvbzxBNP6PTp007NYdiwYTp9+rSaNGniVH8AZRMSEqLFixcXa1+/fr1+/vln2Ww2L8wKwJ9NnTpVb7/9tl577TV17dpVc+bMUWxsrPLy8i54H1YL8ClTprAABwA/V8XbE0DZ7Nu3T8OGDVPz5s21YcMG1atXzx77+9//rmuuuUbDhg3T9u3b1bx58xL3kZubq+rVq6tKlSqqUsW5l0BQUJCCgoKc6gug7G6++WYtW7ZMr776qkPeLl68WNHR0Tp69KgXZwdAknr16qVOnTpJku6++27VrVtX06dP14cffqjBgwd7eXYly8vLU7Vq1bw9DQCoNLgC7mdefPFF5eXl6Y033nBYfEtSeHi4Xn/9deXm5mratGmS/vc77127dmnIkCG66KKLdPXVVzvE/uz06dP6v//7P4WHh6tmzZrq16+ffvnlFwUEBOipp56yb1fSb8CbNm2qPn36aOPGjerSpYtCQkLUvHlzLVq0yGGM48eP6+GHH1a7du1Uo0YN1apVS7169dK3337rwjMFVCyDBw/WsWPHtGbNGntbQUGB3n//fQ0ZMqTY9i+99JK6du2qunXrKjQ0VNHR0SX+jnvNmjW6+uqrVbt2bdWoUUOtW7fWxIkTLeeSn5+vPn36KCwsTF988UX5Dw6ooK6//npJ0oEDBy4oJwMCApSbm6u33nrL/nX2kSNH6qmnntIjjzwiSWrWrJk99uf34HfeeUfR0dEKDQ1VnTp1NGjQIB0+fNhh/927d1fbtm2VkZGha6+9VtWqVdPEiRPt91x56aWX9MYbb6hFixay2Wzq3Lmzvv76a/eeJACoZLgC7mc++ugjNW3aVNdcc02J8WuvvVZNmzbVqlWrHNrvuOMOtWzZUs8995wMwzDd/8iRI/Xee+9p2LBhuuqqq7R+/Xr17t37gue3d+9e3X777Ro9erRGjBih+fPna+TIkYqOjtbll18uSdq/f79WrFihO+64Q82aNVNWVpZef/11XXfdddq1a5caNmx4weMBlUXTpk0VGxurJUuWqFevXpKkjz/+WNnZ2Ro0aJBeffVVh+3/8Y9/qF+/fho6dKgKCgqUkpKiO+64QytXrrTn9M6dO9WnTx9dccUVmjp1qmw2m/bu3avPP//cdB6nT5/WLbfcoi1btmjt2rXq3Lmz+w4a8HP79u2TJNWtW1fPPPNMqTn59ttv6+6771aXLl10zz33SJJatGih6tWr64cfftCSJUv0yiuvKDw8XJLsH8Q/++yzevLJJ3XnnXfq7rvv1pEjRzRz5kxde+212rp1q2rXrm2f07Fjx9SrVy8NGjRId911lyIiIuyxxYsX6+TJk7r33nsVEBCgadOm6bbbbtP+/ftVtWpVT5wyAKj4DPiNEydOGJKMW265xXK7fv36GZKMnJwcY/LkyYYkY/DgwcW2Ox87LyMjw5BkjB8/3mG7kSNHGpKMyZMn29sWLFhgSDIOHDhgb2vSpIkhydiwYYO97ffffzdsNpvx0EMP2dvOnDljFBYWOoxx4MABw2azGVOnTnVok2QsWLDA8niBiux8rn399dfGa6+9ZtSsWdPIy8szDMMw7rjjDqNHjx6GYZzLv969e9v7nd/mvIKCAqNt27bG9ddfb2975ZVXDEnGkSNHTMdft26dIclYtmyZcfLkSeO6664zwsPDja1bt7rwKAH/dj5P165daxw5csQ4fPiwkZKSYtStW9cIDQ01fv755wvKScMwjOrVqxsjRowoNsaLL75Y7H3XMAzj4MGDRlBQkPHss886tH/33XdGlSpVHNqvu+46Q5Ixd+5ch23Pv9/WrVvXOH78uL39ww8/NCQZH330UVlOBwDAAl9B9yMnT56UJNWsWdNyu/PxnJwce9t9991X6v5TU1MlSffff79D+wMPPHDBc7zsssscrs7Xq1dPrVu31v79++1tNptNgYHnXnqFhYU6duyY/auv33zzzQWPBVQ2d955p06fPq2VK1fq5MmTWrlyZYlfP5ek0NBQ+3//97//VXZ2tq655hqHHDt/VezDDz9UUVGR5djZ2dm66aabtHv3bqWnp6tDhw7lPh6goomLi1O9evUUFRWlQYMGqUaNGlq+fLkaNWp0QTnpjA8++EBFRUW68847dfToUfsjMjJSLVu21Lp16xy2t9lsGjVqVIn7GjhwoC666CL73+ffz//8Hg4AKB++gu5Hzi+szy/EzZS0UG/WrFmp+//pp58UGBhYbNtLLrnkgufYuHHjYm0XXXSR/vvf/9r/Lioq0j/+8Q/Nnj1bBw4cUGFhoT1Wt27dCx4LqGzq1aunuLg4LV68WHl5eSosLNTtt99e4rYrV67UM888o23btik/P9/e/uf7PgwcOFD//Oc/dffdd2vChAm64YYbdNttt+n222+3f0h23vjx43XmzBlt3brV/nMSAI5mzZqlVq1aqUqVKoqIiFDr1q3tuXQhOemMH3/8UYZhqGXLliXG//rV8UaNGik4OLjEbf/6Hn5+Mf7n93AAQPmwAPcjYWFhatCggbZv32653fbt29WoUSPVqlXL3vbnT97dyezO6Maffnf+3HPP6cknn9Tf/vY3Pf3006pTp44CAwM1fvz4Uq/CAZXdkCFDNGbMGGVmZqpXr14Ov+087z//+Y/69euna6+9VrNnz1aDBg1UtWpVLViwwKGUWWhoqDZs2KB169Zp1apVSk1N1dKlS3X99dfr008/dcjnW265RSkpKXr++ee1aNGiYgt0AFKXLl3sd0H/swvNSWcUFRUpICBAH3/8cYnvwTVq1HD42+r/By7kPRwAUD4swP1Mnz599Oabb2rjxo32u5n/2X/+8x8dPHhQ9957b5n33aRJExUVFenAgQMOn6Tv3bu3XHP+q/fff189evTQvHnzHNpPnDhhv7EMgJLdeuutuvfee7V582YtXbq0xG3+9a9/KSQkRJ988olDffAFCxYU2zYwMFA33HCDbrjhBk2fPl3PPfecHn/8ca1bt05xcXH27fr376+bbrpJI0eOVM2aNTVnzhzXHxxQQZUlJ82uiJu1t2jRQoZhqFmzZmrVqpVrJgwAcBsuYfiZRx55RKGhobr33nt17Ngxh9jx48d13333qVq1avZyJWURHx8vSZo9e7ZD+8yZM52fcAmCgoKKfZq+bNky/fLLLy4dB6iIatSooTlz5uipp55S3759S9wmKChIAQEBDj/vOHjwoFasWOGw3fHjx4v1Pf/b7j9/Rfa84cOH69VXX9XcuXP12GOPOX8QQCVzoTkpSdWrV9eJEydKbJdULHbbbbcpKChIU6ZMKfbeahhGsf9XAAB4F1fA/UzLli311ltvaejQoWrXrp1Gjx6tZs2a6eDBg5o3b56OHj2qJUuWqEWLFmXed3R0tAYMGKAZM2bo2LFj9jJkP/zwg6Ty/07tvD59+mjq1KkaNWqUunbtqu+++07vvvuumjdv7pL9AxXdiBEjLOO9e/fW9OnT1bNnTw0ZMkS///67Zs2apUsuucThJyxTp07Vhg0b1Lt3bzVp0kS///67Zs+erYsvvrjEb9hIUkJCgnJycvT4448rLCys1JrhAC48J6Vz78Vr167V9OnT1bBhQzVr1kwxMTGKjo6WJD3++OMaNGiQqlatqr59+6pFixZ65plnlJSUpIMHD6p///6qWbOmDhw4oOXLl+uee+7Rww8/7I3DBgCUgAW4H7rjjjvUpk0bJScn2xfddevWVY8ePTRx4kS1bdvW6X0vWrRIkZGRWrJkiZYvX664uDgtXbpUrVu3VkhIiEvmP3HiROXm5mrx4sVaunSpOnbsqFWrVmnChAku2T9Q2V1//fWaN2+enn/+eY0fP17NmjXTCy+8oIMHDzr8z36/fv108OBBzZ8/X0ePHlV4eLiuu+46TZkyRWFhYab7nzhxorKzs+2L8HHjxnnisAC/daE5KUnTp0/XPffcoyeeeEKnT5/WiBEjFBMTo86dO+vpp5/W3LlzlZqaav/JWPXq1TVhwgS1atVKr7zyiqZMmSJJioqK0k033aR+/fp545ABACYCDO6sgVJs27ZNV155pd555x0NHTrU29MBAAAAAL/Eb8Dh4PTp08XaZsyYocDAQF177bVemBEAAAAAVAx8BR0Opk2bpoyMDPXo0UNVqlTRxx9/rI8//lj33HOPoqKivD09AAAAAPBbfAUdDtasWaMpU6Zo165dOnXqlBo3bqxhw4bp8ccfV5UqfF4DAAAAAM7iK+hwcOONN2rjxo06fvy4CgoKtHfvXk2ePJnFNwAAgAts2LBBffv2VcOGDRUQEFBiObq/Sk9PV8eOHWWz2XTJJZdo4cKFbp8nAPdgAQ4AAAB4SG5urtq3b69Zs2Zd0PYHDhxQ79691aNHD23btk3jx4/X3XffrU8++cTNMwXgDnwFHQAAAPCCgIAALV++XP379zfd5rHHHtOqVau0Y8cOe9ugQYN04sQJpaamemCWAFzJbd8rnjVrll588UVlZmaqffv2mjlzprp06VJqv6KiIv3666+qWbOmAgIC3DU9wO8ZhqGTJ0+qYcOGCgx0z5dZnM1jiVwGLoQn8lgilwF3c2cub9q0SXFxcQ5t8fHxGj9+vGmf/Px85efn2/8uKirS8ePHVbduXfIYMOGp92QZbpCSkmIEBwcb8+fPN3bu3GmMGTPGqF27tpGVlVVq38OHDxuSePDgcYGPw4cPuyONy5XH5DIPHmV7uCuPyWUePDz7KGsuSzKWL19uuU3Lli2N5557zqFt1apVhiQjLy+vxD6TJ0/2+rngwcNfH+58TzYMw3DLV9BjYmLUuXNnvfbaa5LOfeoWFRWlBx54QBMmTLDsm52drdq1a7t6SkCFdeLECYWFhbl8v+XJY+l/uVxdEp+1AyUzJOXKfXksuS6XKzurq40zZsxwy5hPPvmkaWzJkiWWfW+44QbT2N69e01jLVq0MI0dP37cckyreL169UxjoaGhlvu1UlhYaBo7cuSIaWznzp2mscOHDzs9n7Lm8oV8Bb1Vq1YaNWqUkpKS7G2rV69W7969lZeXV+L5++sV8OzsbDVu3FiHDx9WrVq1Lnh+QGWSk5OjqKgot74nS274CnpBQYEyMjIc/pEIDAxUXFycNm3aVGp/vhYDlI07cqa8efzneQWIBThQGne997kylys7m83m8TFDQkJMY0FBQZZ9reZrVdkkODjYNFa1alXLMZ3dr1WsNFYLcKv5uuvrpe7Il8jISGVlZTm0ZWVlqVatWqYfXthsthJfA7Vq1WIBDpTC3e97Ll+AHz16VIWFhYqIiHBoj4iI0O7du4tt/9dP6HJyclw9JQBlVNY8lshlwBeRy4D/i42N1erVqx3a1qxZo9jYWC/NCEB5eL0MWXJyssLCwuyPqKgob08JgBPIZaBiIJcB9zp16pS2bdumbdu2STpXZmzbtm06dOiQJCkpKUnDhw+3b3/fffdp//79evTRR7V7927Nnj1b7733nh588EFvTB9AObl8AR4eHq6goKASvyoTGRlZbPukpCRlZ2fbH+X53Q0A1yhrHkvkMuCLyGXA92zZskVXXnmlrrzySklSYmKirrzySk2aNEmS9Ntvv9kX45LUrFkzrVq1SmvWrFH79u318ssv65///Kfi4+O9Mn8A5ePyr6AHBwcrOjpaaWlp9htKFBUVKS0tTQkJCcW2N/uNCgDvKWseS+Qy4ItcmcuhoaEl/i4uLy/PdPzGjRtbzu/PiwxfYLWgeeGFF0xj//d//2e531dffdU0duONN5rGHn/8cdNY9+7dnR6zbt26prFPPvnENDZ48GDLMT/99FPT2K233moae/vtt01jd9xxh+WYy5Yts4z7ou7du8vqHsgLFy4ssc/WrVvdOCsAnuKWOuCJiYkaMWKEOnXqpC5dumjGjBnKzc3VqFGj3DEcADcgj4GKgVwGAMB3uGUBPnDgQB05ckSTJk1SZmamOnTooNTU1GI3gQHgu8hjoGIglwEA8B1uWYBLUkJCgunX2wD4B/IYqBjIZQAAfIPX74IOAAAAAEBlwAIcAAAAAAAPYAEOAAAAAIAHBBhWdRC8ICcnR2FhYd6eBuA3srOzVatWLW9Po5jzuVxDUvHCRQAkyZB0Sr6bx1Lp78shISGmsTNnzrhjSl7RoEED09hvv/3mljEHDRpkGktJSbHs26lTJ9PYli1bTGMPPvigaeyVV16xHLNt27amsR07dpjGrMq/WZVF80W+msvn89hX5wf4Ak/lCVfAAQAAAADwABbgAAAAAAB4AAtwAAAAAAA8gAU4AAAAAAAewAIcAAAAAAAPYAEOAAAAAIAHsAAHAAAAAMADqnh7AgCAsiv09gT+IsgiVp65Wu0XvsEbtb779OljGmvTpo1l35deesmpMa1qffft29ey79atW01jY8aMMY199dVXprHPPvvMckyrWt8DBw40jbVs2dI09t1331mO+cMPP5jGHn74YdPYp59+arlfd+jfv79pbMWKFR6bB4DKhyvgAAAAAAB4AAtwAAAAAAA8gAU4AAAAAAAewAIcAAAAAAAPYAEOAAAAAIAHsAAHAAAAAMADKEMGoNKwKoflrnJXvlYuzF38rdSYN14LcJ2VK1c6FXOXjz76yDJuGIZpLCAgwDS2bt0601h4eLjlmJ06dTKNff7556ax119/3TTWsWNHyzGjo6NNY/n5+aax7du3m8Yuu+wyyzGtSqpVrVrVNDZx4kTL/QKAu3AFHAAAAAAAD2ABDgAAAACAB7AABwAAAADAA1iAAwAAAADgASzAAQAAAADwABbgAAAAAAB4AGXIAMBH+Vp5roo0JjyjW7dulnGrclj+5N1337WMt2nTxjRmVS6sT58+prHc3FzLMa3Kd+3atcuyr5k//vjDMl6nTh3TmFW5tR49epjGGjZsaDlmrVq1TGMPPvigZV8A8AaXXwF/6qmnFBAQ4PCweuMB4JvIZcD/kceAb5o1a5aaNm2qkJAQxcTE6KuvvrLcfsaMGWrdurVCQ0MVFRWlBx98UGfOnPHQbAG4kluugF9++eVau3bt/wapwoV2wB+Ry4D/I48B37J06VIlJiZq7ty5iomJ0YwZMxQfH689e/aofv36xbZfvHixJkyYoPnz56tr16764YcfNHLkSAUEBGj69OleOAIA5eGWd+EqVaooMjLSHbsG4EHkMuD/yGPAt0yfPl1jxozRqFGjJElz587VqlWrNH/+fE2YMKHY9l988YW6deumIUOGSJKaNm2qwYMH68svv/TovAG4hltuwvbjjz+qYcOGat68uYYOHapDhw6Zbpufn6+cnByHBwDfQC4D/q8seSyRy4A7FRQUKCMjQ3Fxcfa2wMBAxcXFadOmTSX26dq1qzIyMuxfU9+/f79Wr16tm2++2SNzBuBaLl+Ax8TEaOHChUpNTdWcOXN04MABXXPNNTp58mSJ2ycnJyssLMz+iIqKcvWUADiBXAb8X1nzWCKXAXc6evSoCgsLFRER4dAeERGhzMzMEvsMGTJEU6dO1dVXX62qVauqRYsW6t69uyZOnGg6Dh+kAb7L5QvwXr166Y477tAVV1yh+Ph4rV69WidOnNB7771X4vZJSUnKzs62Pw4fPuzqKQFwArkM+L+y5rFELgO+Jj09Xc8995xmz56tb775Rh988IFWrVqlp59+2rQPH6QBvsvtd2KpXbu2WrVqpb1795YYt9lsstls7p6G11SvXt001rRpU7eMGRoaahobMWKEU/tMSEiwjBcVFTm1308//dQ09uyzz1r2tSqjcvz4cafmA3MVIZetynq5qxSW1Zhu+Q2QJOeysXTuKovma2XIrObjjdJwrlRaHktlz+XRo0ebxubNm2fZ96677jKNvfPOOxc8B28bOnSot6dQjNV7ZHh4uGmsc+fOprGPP/7Ycszo6GjTWNu2bU1jV111lWmstNJnVv8f0apVK9PYyy+/bBrr27ev5ZjlER4erqCgIGVlZTm0Z2Vlmd6r4cknn9SwYcN09913S5LatWun3Nxc3XPPPXr88ccVGFj83SQpKUmJiYn2v3NycliEAz7CXf//Z3fq1Cnt27dPDRo0cPdQANyIXAb8H3kMeFdwcLCio6OVlpZmbysqKlJaWppiY2NL7JOXl1dskR0UdO7jQMMwSuxjs9lUq1YthwcA3+DyBfjDDz+s9evX6+DBg/riiy906623KigoSIMHD3b1UADciFwG/B95DPiexMREvfnmm3rrrbf0/fffa+zYscrNzbXfFX348OFKSkqyb9+3b1/NmTNHKSkpOnDggNasWaMnn3xSffv2tS/EAfgPl38F/eeff9bgwYN17Ngx1atXT1dffbU2b96sevXquXooAG5ELgP+jzwGfM/AgQN15MgRTZo0SZmZmerQoYNSU1PtN2Y7dOiQwxXvJ554QgEBAXriiSf0yy+/qF69eurbt2+pP9UD4JtcvgBPSUlx9S4BeAG5DPg/8hjwTQkJCab310lPT3f4u0qVKpo8ebImT57sgZkBcDe3/wYcAAAAAACwAAcAAAAAwCNYgAMAAAAA4AFurwNe2VnV01y7dq1pLCAgwDRmVnLCnUqr8+3snG688UanYpL0wAMPmMbmzJnj1Hzg/7xRz9tZpdXrrsj1qC+Us7XbSzs/vlZ73J/t3LnTNDZ8+HDLvosWLXL1dPD/3XfffaaxqlWrmsbq169vGrP6fxpJevfdd01jb731lmls2rRpprHLL7/ccszTp0+bxrp27Woa+/XXXy33CwDuwhVwAAAAAAA8gAU4AAAAAAAewAIcAAAAAAAPYAEOAAAAAIAHsAAHAAAAAMADWIADAAAAAOABlCFzsy+++MI09uWXX5rGrrrqKndMx9J///tf09iRI0cs+3799demsWuuucY0tnDhwlLn5cyYqLycLVtVGneUBCttPuaFgkovYebsmO7qa8UdJdUoM+Y5oaGhpjF/KzOWlJRkGmvWrJlpzOocSNJdd91lGtu8ebNpzKpUllW5MEnasmWLacxqvm3atDGNrVu3znLMffv2WcbNHDhwwDSWm5tr2TcoyPxfEKsSqTNnzix9YiYGDx5crO3s2bN6//33nd4ngMqDK+AAAAAAAHgAC3AAAAAAADyABTgAAAAAAB7AAhwAAAAAAA9gAQ4AAAAAgAewAAcAAAAAwAMoQ+ZmBQUFprFu3bqZxj7++GPT2I033uj0fHbt2mUa69u3r2nsp59+cnpMwNWcLTHlayXKylN+yx1l0Urr667SXr5WMswdZdEqstJKU/mT5ORk05hVSavy+Pbbb01jRUXmBQcfeeQRy/0ePHjQNDZ06FDTmM1mM40FBwdbjumsHj16mMa2b99u2ddqvlWrmhdzzMnJMY1ddNFFlmMuWbLEMg4AVrgCDgAAAACAB7AABwAAAADAA1iAAwAAAADgASzAAQAAAADwABbgAAAAAAB4AAtwAAAAAAA8gDJkPqpz585O9/3vf/9rGrv66qtNY1YlOQBf4myZqPKU7nJHqazS9unsmO46TneVKPNG6TNKjblOZGSkaSwzM9Pp/Y4ZM8Y01rNnT9PYZZddZrnfSy+91DT29ttvlz6xEhQWWr9Srd6Xz5w5Yxp74403TGNWJbYkqWnTpqax77//3jTWv39/09jWrVstx3TWjz/+aBr7/fffLftefvnlprHNmzebxqzOn9XzJUlt2rQp1lZYWGh5HABwXpmvgG/YsEF9+/ZVw4YNFRAQoBUrVjjEDcPQpEmT1KBBA4WGhiouLo5/kAAfQx4DFQO5DACAfynzAjw3N1ft27fXrFmzSoxPmzZNr776qubOnasvv/xS1atXV3x8vOUnvAA8izwGKgZyGQAA/1Lmr6D36tVLvXr1KjFmGIZmzJihJ554QrfccoskadGiRYqIiNCKFSs0aNCg8s0WgEuQx0DFQC4DAOBfXHoTtgMHDigzM1NxcXH2trCwMMXExGjTpk0l9snPz1dOTo7DA4D3OJPHErkM+BpyGQAA3+PSBfj5m61EREQ4tEdERJjeiCU5OVlhYWH2R1RUlCunBKCMnMljiVwGfA25DACA7/F6GbKkpCRlZ2fbH4cPH/b2lAA4gVwGKgZyGXC/WbNmqWnTpgoJCVFMTIy++uory+1PnDihcePGqUGDBrLZbGrVqpVWr17todkCcCWXliE7X4okKytLDRo0sLdnZWWpQ4cOJfax2Wyy2WyunAaAcnAmjyVyGfA15DLgm5YuXarExETNnTtXMTExmjFjhuLj47Vnzx7Vr1+/2PYFBQW68cYbVb9+fb3//vtq1KiRfvrpJ9WuXdvzkwdQbi5dgDdr1kyRkZFKS0uzv7nn5OToyy+/1NixY105VIVXp04d05hhGJZ9p06dahrjt3wojb/nsTtqZ0veqVXtDuWZa3nqizu7XyvuGrOi1Aj3VC6Xp9Z3p06dTGNvvvmmU7HSHDx40DT20ksvmcZiY2NNY6XVx87IyDCNBQWZv+IuueQS09i///1vyzGt7N+/3zQ2YMAA01h5zrsVq/NXr149y755eXmmsSVLlpjGunbtahrbt2+f5Zi7d++2jJdm+vTpGjNmjEaNGiVJmjt3rlatWqX58+drwoQJxbafP3++jh8/ri+++MJev9yqzjsA31bmBfipU6e0d+9e+98HDhzQtm3bVKdOHTVu3Fjjx4/XM888o5YtW6pZs2Z68skn1bBhQ/Xv39+V8wZQDuQxUDGQy4B/KSgoUEZGhpKSkuxtgYGBiouLM7054r///W/FxsZq3Lhx+vDDD1WvXj0NGTJEjz32mOkHOPn5+crPz7f/zQUYwHeUeQG+ZcsW9ejRw/53YmKiJGnEiBFauHChHn30UeXm5uqee+7RiRMndPXVVys1NVUhISGumzWAciGPgYqBXAb8y9GjR1VYWFjizRHNrqzv379fn332mYYOHarVq1dr7969uv/++3X27FlNnjy5xD7JycmaMmWKy+cPoPzKvADv3r275VegAwICNHXqVMuvQQPwLvIYqBjIZaDiKyoqUv369fXGG28oKChI0dHR+uWXX/Tiiy+aLsCTkpLsH8hJ566AU9EA8A0u/Q04AAAAgJKFh4crKChIWVlZDu1ZWVn2Gyf+VYMGDVS1alWHr5tfeumlyszMVEFBgYKDg4v14WaKgO/yehkyAAAAoDIIDg5WdHS00tLS7G1FRUVKS0szvdFft27dtHfvXhUVFdnbfvjhBzVo0KDExTcA38YCHAAAAPCQxMREvfnmm3rrrbf0/fffa+zYscrNzbXfFX348OEON2kbO3asjh8/rr///e/64YcftGrVKj333HMaN26ctw4BQDnwFXQfZfWbvtLKkH399deung7gN5wtIVVaKSx3lTez4mzps/KU0bL6VLbIImbFXecA/u/UqVOmsYceesg09vLLL5vGunXrZjnmJ598YhpztrTTr7/+ahlv1aqVaexvf/ubU2N6w2effeaW/YaFhZnGzL6Wfd7FF1/s1Jh/rh7wV7169bLs+/HHHzs15nkDBw7UkSNHNGnSJGVmZqpDhw5KTU2135jt0KFDCgz837/GUVFR+uSTT/Tggw/qiiuuUKNGjfT3v/9djz32WLnmAcA7WIADAAAAHpSQkKCEhIQSY+np6cXaYmNjtXnzZjfPCoAn8BV0AAAAAAA8gAU4AAAAAAAewAIcAAAAAAAPYAEOAAAAAIAHsAAHAAAAAMADuAu6j7r33ntNYzNnzrTs++mnn5rG8vLyTGM7duwwjW3cuNFyTKvSaGfOnDGNvf7666axEydOWI6JystdJbic5Wy5MHeNWR4VpdSYu847iqtTp45p7Pjx45Z9e/bsaRqzKjVm5fPPP7eMJyYmmsas3ntXrVplGlu3bp3lmE2aNLGM+4slS5a4Zb+DBg0yjVn9f4tkXU7MyqOPPmoae/jhh53aJwBcCK6AAwAAAADgASzAAQAAAADwABbgAAAAAAB4AAtwAAAAAAA8gAU4AAAAAAAewAIcAAAAAAAPoAyZj/rnP/9pGrMq+SVJQ4YMMY3Vrl3bNNa9e3fTWGCg9Wc14eHhprHLLrvMNDZ+/HjT2P3332855vLlyy3jqLicLVvlrtJUvlYWrTyfrFrN96xFrKqT/ST3nL/S+jn7WvC159oXWJUa69+/v2XfGTNmODXm2LFjTWO33nqrZV+rslWzZ882jZX2nmTl7NnSsqByu/HGG53u+/bbbzvVr169ek6PCQDlwRVwAAAAAAA8gAU4AAAAAAAewAIcAAAAAAAPYAEOAAAAAIAHsAAHAAAAAMADWIADAAAAAOABLMABAAAAAPCAMtcB37Bhg1588UVlZGTot99+0/Llyx3qfI4cOVJvvfWWQ5/4+HilpqaWe7I4Z968eU7Hq1evbhpr0qSJaWzXrl2WY9aqVcs0ZlWTdeLEiaaxZcuWWY45bNgw09iSJUss+1Z25LFrWdV/Lk/daGf7FlnESvvU1apasdV8ylNj3Z/qZ/vaXH0hl5988knT2NNPP+2ycf6sR48eprH9+/db9i0sNH+19uzZ0zRWnuNs3769aezXX3+17FtRdO/e3TQ2ZswY09jvv/9uud8TJ044NZ8aNWo41Q8AyqvMV8Bzc3PVvn17zZo1y3Sbnj176rfffrM/WAwBvoU8BioGchkAAP9S5ivgvXr1Uq9evSy3sdlsioyMdHpSANyLPAYqBnIZAAD/4pbfgKenp6t+/fpq3bq1xo4dq2PHjplum5+fr5ycHIcHAO8rSx5L5DLgq8hlAAB8h8sX4D179tSiRYuUlpamF154QevXr1evXr1Mf3OVnJyssLAw+yMqKsrVUwJQRmXNY4lcBnwRuQwAgG8p81fQSzNo0CD7f7dr105XXHGFWrRoofT0dN1www3Ftk9KSlJiYqL975ycHN7sAS8rax5L5DLgi8hlAAB8i9vLkDVv3lzh4eHau3dviXGbzaZatWo5PAD4ltLyWCKXAX9ALgMA4F0uvwL+Vz///LOOHTumBg0auHsoXIDc3FzTWGmlxqxY/UbwryVw/uynn34yjaWlpVmO2aJFi9InBpfwpzwuTzksZ1l9klmeTzmd7WtVhswqJpWvbJqzvDGmr5UT85Ty5PLLL7+s0NDQYu3333+/K6ZWjFVpr3379pnGSprjn508edI0FhhonnVWpbKsymJKUkhIiGmscePGln0rivT0dKdipbEqb2ZlwIABTo8JAOVR5gX4qVOnHD45P3DggLZt26Y6deqoTp06mjJligYMGKDIyEjt27dPjz76qC655BLFx8e7dOIAnEceAxUDuQwAgH8p8wWWLVu26Morr9SVV14pSUpMTNSVV16pSZMmKSgoSNu3b1e/fv3UqlUrjR49WtHR0frPf/4jm83m8skDcA55DFQM5DLgn2bNmqWmTZsqJCREMTEx+uqrry6oX0pKigICAtS/f3/3ThCA25T5Cnj37t1lGIZp/JNPPinXhAC4H3kMVAzkMuB/li5dqsTERM2dO1cxMTGaMWOG4uPjtWfPHtWvX9+038GDB/Xwww/rmmuu8eBsAbia22/CBgAAAOCc6dOna8yYMRo1apQuu+wyzZ07V9WqVdP8+fNN+xQWFmro0KGaMmWKmjdv7sHZAnA1FuAAAACABxQUFCgjI0NxcXH2tsDAQMXFxWnTpk2m/aZOnar69etr9OjRFzROfn6+cnJyHB4AfAMLcAAAAMADjh49qsLCQkVERDi0R0REKDMzs8Q+Gzdu1Lx58/Tmm29e8DjJyckKCwuzP6Kioso1bwCu4/YyZICzrH7XKEkDBw40jT3zzDOung4qOauyVValvcrzKafVfp0tt+au8lvu+jTX2RJlpZ2fylqGrDweeughl+9z3LhxprHCQvNnMT8/3zRW2ntH7dq1TWM7duwwjcXExJjGjh07Zjnmxx9/bBn3tBtvvNE0FhkZaRr781XbkowYMcI09v7775vGbr/9dtPYv//9b8sx+/XrZxn3dydPntSwYcP05ptvKjw8/IL7JSUlKTEx0f53Tk4Oi3DAR7AABwAAADwgPDxcQUFBysrKcmjPysoq8cOPffv26eDBg+rbt6+9rajo3MezVapU0Z49e9SiRYti/Ww2G9UOAB/FV9ABAAAADwgODlZ0dLTS0tLsbUVFRUpLS1NsbGyx7du0aaPvvvtO27Ztsz/69eunHj16aNu2bVzVBvwQV8ABAAAAD0lMTNSIESPUqVMndenSRTNmzFBubq5GjRolSRo+fLgaNWqk5ORkhYSEqG3btg79z/+M4q/tAPwDC3AAAADAQwYOHKgjR45o0qRJyszMVIcOHZSammq/MduhQ4cUGMiXVIGKigU4AAAA4EEJCQlKSEgoMZaenm7Zd+HCha6fEACP4eM1AAAAAAA8gCvgcLvq1aubxqZNm+bBmaAyKE9pKmdZ7dddY1qxOgfl+dTV147TG2PCtXJzc01j5+/0XJK/1lAuiz/++MM0durUKdPYG2+8YRqrUaOG5ZibNm0yjYWFhZnGhgwZYhrbvXu35Zjr1q0zja1Zs8ayr5m3337bqX6SdakxK94oM1ba3cOtyuABQGm4Ag4AAAAAgAewAAcAAAAAwANYgAMAAAAA4AEswAEAAAAA8AAW4AAAAAAAeAALcAAAAAAAPIAFOAAAAAAAHkAdcLhdQkKCaaxjx45O7/fXX391ui9QVlY1p52tPW7Vr7S+zjKvrFz6mKXN1x28UbvdG8fpD+bMmaPQ0NBi7e+8845pn7Vr11ru06qe9wsvvGAae/zxx01jISEhlmOWdAznBQWZP/tW9bpzcnIsx+zcubNpLDg42DQ2Z84cy/06a8uWLaaxb7/91jT2yiuvWO53x44dprEbb7zRNOZsXXJ3Ka3Od0l1wg3DUEFBgbumBKAC4Qo4AAAAAAAewAIcAAAAAAAPYAEOAAAAAIAHsAAHAAAAAMADWIADAAAAAOABLMABAAAAAPCAMpUhS05O1gcffKDdu3crNDRUXbt21QsvvKDWrVvbtzlz5oweeughpaSkKD8/X/Hx8Zo9e7ZlqRH4vjp16ljGrUrCWJUhK49nn33WLfutDMhl13K2VFZ5Smy5q1SWs/v1Rrk1Z8u/ldbXWZ4e09N5PHbsWFdO3z4/Z+zcudM01qxZM8u+Bw4cMI21bdvWNFZYaP4Ml1YW02pOjRs3No1dffXVprGNGzdajmlV9qtTp06WfZ3VtWtX05hVqbHLL7/cNGb1XLtLaSVSv/nmGw/NBEBFVKYr4OvXr9e4ceO0efNmrVmzRmfPntVNN92k3Nxc+zYPPvigPvroIy1btkzr16/Xr7/+qttuu83lEwfgPHIZ8H/kMQAA/qdMV8BTU1Md/l64cKHq16+vjIwMXXvttcrOzta8efO0ePFiXX/99ZKkBQsW6NJLL9XmzZt11VVXuW7mAJxGLgP+jzwGAMD/lOs34NnZ2ZL+9/XkjIwMnT17VnFxcfZt2rRpo8aNG2vTpk0l7iM/P185OTkODwCeRS4D/s8VeSyRywAAuJPTC/CioiKNHz9e3bp1s/9mKjMzU8HBwapdu7bDthEREcrMzCxxP8nJyQoLC7M/oqKinJ0SACeQy4D/c1UeS+QyAADu5PQCfNy4cdqxY4dSUlLKNYGkpCRlZ2fbH4cPHy7X/gCUDbkM+D9X5bFELgMA4E5l+g34eQkJCVq5cqU2bNigiy++2N4eGRmpgoICnThxwuET96ysLEVGRpa4L5vNJpvN5sw0AJQTuQz4P1fmsUQuAwDgTmVagBuGoQceeEDLly9Xenp6sbIa0dHRqlq1qtLS0jRgwABJ0p49e3To0CHFxsa6btZwi0suucQ09sEHH1j2tSoh4qzBgwdbxjds2ODyMSsLcrnsvFG2yhusvhZ11sl9euM43VWmzZfG9HQeL1myRNWqVSvWfssttzh3AJL279/vVL/du3ebxlasWOHkbKyFh4ebxjp37mzZNy8vzzTWrVs301hYWJhprLQyZFZlv3r06GEa27p1q2ns5MmTlmN+8cUXlnEz3ig1ZoUyYwDcqUwL8HHjxmnx4sX68MMPVbNmTftvyMLCwhQaGqqwsDCNHj1aiYmJqlOnjmrVqqUHHnhAsbGx3G0V8CHkMuD/yGMAAPxPmRbgc+bMkSR1797doX3BggUaOXKkJOmVV15RYGCgBgwYoPz8fMXHx2v27NkumSwA1yCXAf9HHgMA4H/K/BX00oSEhGjWrFmaNWuW05MC4F7kMuD/yGMAAPxPueqAAwAAAACAC8MCHAAAAAAAD2ABDgAAAACABzhVBxy+LSQkxDR23333mcamTp1qGqtevbrlmFa/RczIyDCNPfroo6axLVu2WI4JlFV5ykS5o5RWeeZj9elpUTn2a9XXar7uKjXmjXJiKFlppSGd8dFHHznVLzo62jRmVaJMkgYOHGgaW7p0qWns6NGjprHGjRtbjrlt2zbT2FtvvWXZ11l33nmnaey9994zjfXp08c09uWXX1qOeffdd5vGkpOTLftWNrNmzdKLL76ozMxMtW/fXjNnzlSXLl1K3PbNN9/UokWLtGPHDknnXv/PPfec6fYAfBtXwAEAAAAPWbp0qRITEzV58mR98803at++veLj4/X777+XuH16eroGDx6sdevWadOmTYqKitJNN92kX375xcMzB+AKLMABAAAAD5k+fbrGjBmjUaNG6bLLLtPcuXNVrVo1zZ8/v8Tt3333Xd1///3q0KGD2rRpo3/+858qKipSWlqah2cOwBVYgAMAAAAeUFBQoIyMDMXFxdnbAgMDFRcXp02bNl3QPvLy8nT27FnVqVPHdJv8/Hzl5OQ4PAD4BhbgAAAAgAccPXpUhYWFioiIcGiPiIhQZmbmBe3jscceU8OGDR0W8X+VnJyssLAw+yMqKqpc8wbgOizAAQAAAD/w/PPPKyUlRcuXL7e86W5SUpKys7Ptj8OHD3twlgCscBd0AAAAwAPCw8MVFBSkrKwsh/asrCxFRkZa9n3ppZf0/PPPa+3atbriiisst7XZbLLZbOWeLwDX4wo4AAAA4AHBwcGKjo52uIHa+RuqxcbGmvabNm2ann76aaWmpqpTp06emCoAN+EKeAVkVcPzpZdecsuYu3btMo3dfPPNprFjx465YzqAyzlbA9tddayt6nWXp0a4u+p5O8vZ+fhi/fCSjsXw+Cw8q3fv3pbxM2fOmMas7vBsVXd70KBBlmPGxMSYxpo3b24as6pjvWjRIssxT58+bRobPXq0aWzevHmmsbFjx1qOOWfOHNPYrbfeahqzqi0dHx9vOeYDDzxgGa8oevbsWaztjz/+0Nq1ay+of2JiokaMGKFOnTqpS5cumjFjhnJzczVq1ChJ0vDhw9WoUSP7a+6FF17QpEmTtHjxYjVt2tT+W/EaNWqoRo0aLjoqAJ7CAhwAAADwkIEDB+rIkSOaNGmSMjMz1aFDB6WmptpvzHbo0CEFBv7vo9Q5c+aooKBAt99+u8N+Jk+erKeeesqTUwfgAizAAQAAAA9KSEhQQkJCibH09HSHvw8ePOj+CQHwGH4DDgAAAACAB7AABwAAAADAA1iAAwAAAADgASzAAQAAAADwAG7CVgG99tprLt/n+vXrLeMzZ840jVFqDJVZeUqUOdv3bDnGdJYvlv1yVk4181hGnnlsQCn7PV5CW0UvQ7Zq1Sq37NeqJFhpevTo4dR+bTabacyqzFhprEqNWZUECwqyzrpHHnnENDZ8+HDTmFVJtZ9//tlyTGcFBASYxgzD+SwpT18rVvMFgNJwBRwAAAAAAA9gAQ4AAAAAgAewAAcAAAAAwANYgAMAAAAA4AEswAEAAAAA8AAW4AAAAAAAeECZypAlJyfrgw8+0O7duxUaGqquXbvqhRdeUOvWre3bdO/evVjJqnvvvVdz5851zYxRqpSUFNPYbbfdZhp79tlnTWOvv/56ueYE30Iu+warMmPu6lueMZ3dr7vKrZWH5XnIPWIa6hFQzzSWU0rJo+ollC4qT5Gkip7HY8eONY3NmTPH6f3ee++9TvXLz893ekxnffXVV07FJOn99983jVmVNytPSTVnRUdHm8a2bNli2XfSpElOjVme0me9e/cu1nb27Fl9+umnTs0FQOVSpivg69ev17hx47R582atWbNGZ8+e1U033aTc3FyH7caMGaPffvvN/pg2bZpLJw2gfMhlwP+RxwAA+J8yXQFPTU11+HvhwoWqX7++MjIydO2119rbq1WrpsjISNfMEIDLkcuA/yOPAQDwP+X6DXh2drYkqU6dOg7t7777rsLDw9W2bVslJSUpLy/PdB/5+fnKyclxeADwLHIZ8H+uyGOJXAYAwJ3KdAX8z4qKijR+/Hh169ZNbdu2tbcPGTJETZo0UcOGDbV9+3Y99thj2rNnjz744IMS95OcnKwpU6Y4Ow0A5UQuA/7PVXkskcsAALiT0wvwcePGaceOHdq4caND+z333GP/73bt2qlBgwa64YYbtG/fPrVo0aLYfpKSkpSYmGj/OycnR1FRUc5OC0AZkcuA/3NVHkvkMgAA7uTUAjwhIUErV67Uhg0bdPHFF1tuGxMTI0nau3dviW/2NptNNpvNmWkAKCdyGfB/rsxjiVwGAMCdyrQANwxDDzzwgJYvX6709HQ1a9as1D7btm2TJDVo0MCpCaLsxo8f71QMlQe57FrOlspyV0mw8nBX2S9/GvN6i1JjVupblDWSpNkltJ2WZF5sy5qn8/jll19WaGhosfb777+/zPu6EOUpNQbp9ttvd/k+/1ziriQnT540jXXt2tU0ZlUyrTRTp041jTn7U4rjx49bxleuXFmsLScnR2FhYU6NB6ByKdMCfNy4cVq8eLE+/PBD1axZU5mZmZKksLAwhYaGat++fVq8eLFuvvlm1a1bV9u3b9eDDz6oa6+9VldccYVbDgBA2ZHLgP8jjwEA8D9lWoCf/zS6e/fuDu0LFizQyJEjFRwcrLVr12rGjBnKzc1VVFSUBgwYoCeeeMJlEwZQfuQy4P/IYwAA/E+Zv4JuJSoqSuvXry/XhAC4H7kM+D/yGAAA/1OuOuAAAAAAAODCsAAHAAAAAMADWIADAAAAAOABLMABAAAAAPCAMt2EDQDgOt6of+1vrGqll+f8We33M2OFRbS9aaRugHUd7hFGx2JtOTmFGhv2rWU/X/HQQw95ewrwgObNm5vGLr74Ysu+x44dM40FBZlnbGCg+fWgoqIiyzEHDRpkGTdjdRPDH374wbJvnTp1nBoTACSugAMAAAAA4BEswAEAAAAA8AAW4AAAAIAHzZo1S02bNlVISIhiYmL01VdfWW6/bNkytWnTRiEhIWrXrp1Wr17toZkCcDUW4AAAAICHLF26VImJiZo8ebK++eYbtW/fXvHx8fr9999L3P6LL77Q4MGDNXr0aG3dulX9+/dX//79tWPHDg/PHIArsAAHAAAAPGT69OkaM2aMRo0apcsuu0xz585VtWrVNH/+/BK3/8c//qGePXvqkUce0aWXXqqnn35aHTt21GuvvebhmQNwBZ+7C7rVXSkBFOerOXN+Xr45O/gLq9dPeV5bVn1zcvIsoied2ue5/Ra/9/r5Nl/NY8m35wbXs7rr+B9//GHZt7DQvL7A2bNnTWPleY1Z7TcnJ8epfZ46dcoyXtJ+z7eVdiwFBQXKyMhQUlKSvS0wMFBxcXHatGlTiX02bdqkxMREh7b4+HitWLHCdJz8/Hzl5+fb/87OzjadO4BzLjSPy8vnFuAnT5r/zw2A4k6ePKmwsDBvT6OY87mc6+V5AGUVFjbETfs1Lzfmq3ks8b5c2Rw8eNCpWGm+++47p/ta+de//uVUzF1Ky+WjR4+qsLBQERERDu0RERHavXt3iX0yMzNL3D4zM9N0nOTkZE2ZMqVYe1RUlNX0AehcSUV3vif73AK8YcOGOnz4sGrWrKmAgADl5OQoKipKhw8fVq1atbw9PZ/D+bFWkc+PYRg6efKkGjZs6O2plIhcLhvOj7WKen58PY8lx1w+efJkhXweXKWivk5dqaKeI1/L5aSkJIer5idOnFCTJk106NAhn/2w70JVlNdQRTkOqeIcS3Z2tho3bqw6deq4dRyfW4AHBgbq4osvLtZeq1Ytv35C3Y3zY62inh9ffhMll53D+bFWEc+PL+ex5JjLAQEBkirm8+BKnJ/SVcRzdCG5HB4erqCgIGVlZTm0Z2VlKTIyssQ+kZGRZdpekmw2m2w2W4lzrCjnvaK8hirKcUgV51gCA917mzRuwgYAAAB4QHBwsKKjo5WWlmZvKyoqUlpammJjY0vsExsb67C9JK1Zs8Z0ewC+zeeugAMAAAAVVWJiokaMGKFOnTqpS5cumjFjhnJzczVq1ChJ0vDhw9WoUSMlJydLkv7+97/ruuuu08svv6zevXsrJSVFW7Zs0RtvvOHNwwDgJJ9fgNtsNk2ePLnEr9GA81Mazo/v4LmwxvmxxvnxDTwP1jg/peMcSQMHDtSRI0c0adIkZWZmqkOHDkpNTbXfaO3QoUMOX4Ht2rWrFi9erCeeeEITJ05Uy5YttWLFCrVt2/aCx6xI572iHEtFOQ6p4hyLp44jwKC+CAAAAAAAbsdvwAEAAAAA8AAW4AAAAAAAeAALcAAAAAAAPIAFOAAAAAAAHuDTC/BZs2apadOmCgkJUUxMjL766itvT8lrNmzYoL59+6phw4YKCAjQihUrHOKGYWjSpElq0KCBQkNDFRcXpx9//NE7k/WC5ORkde7cWTVr1lT9+vXVv39/7dmzx2GbM2fOaNy4capbt65q1KihAQMGKCsry0szrlzI5f8hl82Rx76PXD6HPLZGLntGWfNx2bJlatOmjUJCQtSuXTutXr3aIe6t121ZjuPNN9/UNddco4suukgXXXSR4uLiim0/cuRIBQQEODx69uzp7sOQVLZjWbhwYbF5hoSEOGzjD89J9+7dix1HQECAevfubd/GW89Jaf9WlyQ9PV0dO3aUzWbTJZdcooULFxbbptzvhYaPSklJMYKDg4358+cbO3fuNMaMGWPUrl3byMrK8vbUvGL16tXG448/bnzwwQeGJGP58uUO8eeff94ICwszVqxYYXz77bdGv379jGbNmhmnT5/2zoQ9LD4+3liwYIGxY8cOY9u2bcbNN99sNG7c2Dh16pR9m/vuu8+Iiooy0tLSjC1bthhXXXWV0bVrVy/OunIglx2Ry+bIY99GLv8PeWyNXHa/subj559/bgQFBRnTpk0zdu3aZTzxxBNG1apVje+++86+jTdet2U9jiFDhhizZs0ytm7danz//ffGyJEjjbCwMOPnn3+2bzNixAijZ8+exm+//WZ/HD9+3G3H4OyxLFiwwKhVq5bDPDMzMx228Yfn5NixYw7HsGPHDiMoKMhYsGCBfRtvPSel/Vv9V/v37zeqVatmJCYmGrt27TJmzpxpBAUFGampqfZtXPFe6LML8C5duhjjxo2z/11YWGg0bNjQSE5O9uKsfMNfX0BFRUVGZGSk8eKLL9rbTpw4YdhsNmPJkiVemKH3/f7774YkY/369YZhnDsfVatWNZYtW2bf5vvvvzckGZs2bfLWNCsFctkcuWyNPPYt5HLJyOPSkcuuV9Z8vPPOO43evXs7tMXExBj33nuvYRjee92W99+VP/74w6hZs6bx1ltv2dtGjBhh3HLLLa6eaqnKeiwLFiwwwsLCTPfnr8/JK6+8YtSsWdPhAzdvPSd/diEL8EcffdS4/PLLHdoGDhxoxMfH2/92xXuhT34FvaCgQBkZGYqLi7O3BQYGKi4uTps2bfLizHzTgQMHlJmZ6XC+wsLCFBMTU2nPV3Z2tiSpTp06kqSMjAydPXvW4Ry1adNGjRs3rrTnyBPI5bIhlx2Rx76DXL5w5HFx5LJrOZOPmzZtcthekuLj4+3be+N164p/V/Ly8nT27Fn7a+u89PR01a9fX61bt9bYsWN17Ngxl879r5w9llOnTqlJkyaKiorSLbfcop07d9pj/vqczJs3T4MGDVL16tUd2j39nDijtDxx1XuhTy7Ajx49qsLCQkVERDi0R0REKDMz00uz8l3nzwnn65yioiKNHz9e3bp1U9u2bSWdO0fBwcGqXbu2w7aV9Rx5CrlcNuTy/5DHvoVcvnDksSNy2fWcycfMzEzL7b3xunXFvyuPPfaYGjZs6LAg6tmzpxYtWqS0tDS98MILWr9+vXr16qXCwkKXzv/PnDmW1q1ba/78+frwww/1zjvvqKioSF27dtXPP/8syT+fk6+++ko7duzQ3Xff7dDujefEGWZ5kpOTo9OnT7vsvbCKS2YL+JBx48Zpx44d2rhxo7enAsBJ5DFQMZDLcJfnn39eKSkpSk9Pd7h52aBBg+z/3a5dO11xxRVq0aKF0tPTdcMNN3hjqiWKjY1VbGys/e+uXbvq0ksv1euvv66nn37aizNz3rx589SuXTt16dLFod1fnhNP8ckr4OHh4QoKCip2N8ysrCxFRkZ6aVa+6/w54XxJCQkJWrlypdatW6eLL77Y3h4ZGamCggKdOHHCYfvKeI48iVwuG3L5HPLY95DLF448/h9y2T2cycfIyEjL7b3xui3PvysvvfSSnn/+eX366ae64oorLLdt3ry5wsPDtXfv3nLP2Ywr/o2sWrWqrrzySvs8/e05yc3NVUpKikaPHl3qOJ54Tpxhlie1atVSaGioy94LfXIBHhwcrOjoaKWlpdnbioqKlJaW5vBJEc5p1qyZIiMjHc5XTk6Ovvzyy0pzvgzDUEJCgpYvX67PPvtMzZo1c4hHR0eratWqDudoz549OnToUKU5R95ALpdNZc9l8th3kcsXrrLnsUQuu5sz+RgbG+uwvSStWbPGvr03XrfO/rsybdo0Pf3000pNTVWnTp1KHefnn3/WsWPH1KBBA5fMuySu+DeysLBQ3333nX2e/vScSOfK3OXn5+uuu+4qdRxPPCfOKC1PXPZeeMG3a/OwlJQUw2azGQsXLjR27dpl3HPPPUbt2rWL3Z6/sjh58qSxdetWY+vWrYYkY/r06cbWrVuNn376yTCMc2UKateubXz44YfG9u3bjVtuuaVSlTwZO3asERYWZqSnpzuUOMjLy7Nvc9999xmNGzc2PvvsM2PLli1GbGysERsb68VZVw7ksiNy2Rx57NvI5f8hj62Ry+5XWj4OGzbMmDBhgn37zz//3KhSpYrx0ksvGd9//70xefLkEsuQefp1W9bjeP75543g4GDj/fffd3htnTx50jCMc7n58MMPG5s2bTIOHDhgrF271ujYsaPRsmVL48yZM247DmeOZcqUKcYnn3xi7Nu3z8jIyDAGDRpkhISEGDt37nQ4Xl9/Ts67+uqrjYEDBxZr9+ZzUtq/1RMmTDCGDRtm3/58GbJHHnnE+P77741Zs2aVWIasvO+FPrsANwzDmDlzptG4cWMjODjY6NKli7F582ZvT8lr1q1bZ0gq9hgxYoRhGOdKFTz55JNGRESEYbPZjBtuuMHYs2ePdyftQSWdG0kONQhPnz5t3H///cZFF11kVKtWzbj11luN3377zXuTrkTI5f8hl82Rx76PXD6HPLZGLnuGVT5ed9119tfjee+9957RqlUrIzg42Lj88suNVatWOcS99boty3E0adKkxNfW5MmTDcMwjLy8POOmm24y6tWrZ1StWtVo0qSJMWbMGI99UFiWYxk/frx924iICOPmm282vvnmG4f9+cNzYhiGsXv3bkOS8emnnxbblzefk9L+rR4xYoRx3XXXFevToUMHIzg42GjevLnDv1vnlfe9MMAwDOPCr5cDAAAAAABn+ORvwAEAAAAAqGhYgAMAAAAA4AEswAEAAAAA8AAW4AAAAAAAeAALcAAAAAAAPIAFOAAAAAAAHsACHAAAAAAAD2ABDgAAAACAB7AABwAAAADAA1iAAwAAAADgASzAAQAAAADwABbgAAAAAAB4wP8DLc7dlEtsXB8AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1200x300 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_classes = 10\n",
        "N = 100\n",
        "num_steps = 1000\n",
        "lambda_mask = 0.1\n",
        "lr = 1e-2\n",
        "threshold = 2.5\n",
        "seed = 42\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "mask_list = []\n",
        "pattern_list = []\n",
        "mask_norms = []\n",
        "for t in range(num_classes):\n",
        "    imgs, _ = select_non_target_images(test_data, t, N, seed)\n",
        "    imgs = imgs.to(device)\n",
        "    mask, pattern, mask_norm = optimize_trigger(badnet, imgs, t, num_steps=num_steps, lambda_mask=lambda_mask, lr=lr, device=device)\n",
        "    mask_list.append(mask)\n",
        "    pattern_list.append(pattern)\n",
        "    mask_norms.append(mask_norm)\n",
        "median_norm, mad, anomaly_indices = compute_mad_and_anomaly(mask_norms)\n",
        "print(f\"Mask norms per class: {[f'{n:.6f}' for n in mask_norms]}\")\n",
        "print(f\"median_norm: {median_norm:.6f}, mad: {mad:.6f}\")\n",
        "flagged = []\n",
        "for t in range(num_classes):\n",
        "    is_flagged = anomaly_indices[t] >= threshold\n",
        "    print(f\"Class {t}: norm={mask_norms[t]:.6f}, anomaly_index={anomaly_indices[t]:.3f}, flagged={is_flagged}\")\n",
        "    if is_flagged:\n",
        "        flagged.append(t)\n",
        "if flagged:\n",
        "    print(f\"Flagged backdoor candidate(s): {flagged} with anomaly_index >= {threshold}\")\n",
        "else:\n",
        "    print(f\"No class flagged as backdoor (all anomaly_index < {threshold})\")\n",
        "# Visualize top flagged triggers\n",
        "import matplotlib.pyplot as plt\n",
        "def show_trigger(mask, pattern, example_img, title):\n",
        "    fig, axs = plt.subplots(1, 4, figsize=(12,3))\n",
        "    axs[0].imshow(example_img.squeeze(), cmap='gray')\n",
        "    axs[0].set_title('Original')\n",
        "    axs[1].imshow(mask, cmap='hot')\n",
        "    axs[1].set_title('Mask')\n",
        "    axs[2].imshow(pattern.squeeze(), cmap='gray')\n",
        "    axs[2].set_title('Pattern')\n",
        "    triggered = (1 - mask) * example_img + mask * pattern.squeeze()\n",
        "    axs[3].imshow(triggered, cmap='gray')\n",
        "    axs[3].set_title('Triggered')\n",
        "    for ax in axs: ax.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "# Show triggers for flagged classes (or top 2 smallest mask_norms)\n",
        "show_classes = flagged if flagged else np.argsort(mask_norms)[:2]\n",
        "for t in show_classes:\n",
        "    imgs, _ = select_non_target_images(test_data, t, 1, seed)\n",
        "    show_trigger(mask_list[t], pattern_list[t], imgs[0], f\"Class {t} Trigger\")\n",
        "# Acceptance checks\n",
        "assert all((mask.numpy() >= -1e-3).all() and (mask.numpy() <= 1+1e-3).all() for mask in mask_list), \"Masks not in [0,1]\"\n",
        "assert len(mask_norms) == num_classes, \"mask_norms length mismatch\"\n",
        "assert mad >= 0, \"MAD negative\"\n",
        "# Demonstrate ASR-like measurement for flagged class\n",
        "if flagged:\n",
        "    t = flagged[0]\n",
        "    imgs, _ = select_non_target_images(test_data, t, 20, seed+1)\n",
        "    mask = mask_list[t]\n",
        "    pattern = pattern_list[t]\n",
        "    imgs_trig = (1 - mask) * imgs + mask * pattern.squeeze()\n",
        "    with torch.inference_mode():\n",
        "        outputs = badnet(imgs_trig.to(device))\n",
        "        preds = outputs.argmax(dim=1)\n",
        "    print(f\"Predictions for triggered images (should be {t}):\", preds.cpu().numpy())\n",
        "    print(f\"Fraction predicted as {t}: {(preds == t).float().mean().item():.2%}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "A2QEl3qMZxeW"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
